---
layout: single
title: "Experience"
permalink: /Experience/
date: 2023-8-12
categories: pages
---

<div style="text-align: justify;">
  <p style="line-height: 1.5; font-size: 18px;">
      <strong> I. University of Arizona, Department of Pediatrics </strong>                                      
            <strong>Graduate Research Assistant </strong>
                  <strong>Feb 2023 - Present</strong>
   </p>
     <br>
       <p style="line-height: 1.5;font-size: 15px;">
        
1. **Thorough Data Extraction and Standardization in REDCap:**
   I exhibit a strong ability to extract data from various sources and transform them into standardized formats using the REDCap platform. This involves a meticulous approach to ensure that data is accurately captured and formatted for further analysis. By effectively managing the data extraction process, I contribute to the creation of analytical project databases that serve as the foundation for insightful research and decision-making.

2. **Optimization of Database Programs for Seamless Querying:**
   One of my key strengths lies in optimizing database programs to facilitate smooth and efficient data querying processes. This involves enhancing the performance of database systems, allowing users to retrieve the required information rapidly and without encountering performance bottlenecks. I am also dedicated to implementing robust security measures during data transfers and procedures, safeguarding the integrity of the system and maintaining compliance with data protection regulations.

3. **Precise Data Cleaning and Linkage Protocols with Comprehensive Documentation:**<br>
   I excel at executing data cleaning and data linkage protocols with a high degree of precision. This involves identifying and rectifying inaccuracies, inconsistencies, and missing values within datasets. Importantly, I meticulously maintain detailed work logs that document every step of the data refinement process. These comprehensive records serve as valuable references, ensuring the reproducibility of data cleaning procedures and bolstering the credibility of subsequent analyses.

4. **Creation of Data Pipelines from MariaDB to PostgreSQL using Python:**<br>
   Leveraging my proficiency in Python scripting, I have successfully designed and implemented data pipelines that transfer data from MariaDB to PostgreSQL, transforming and mapping the data to adhere to OMOP (Observational Medical Outcomes Partnership) table structures. This technical capability enables the seamless movement of data between different database systems while ensuring data integrity and compatibility.

5. **Efficient Integration of MTurk Tasks and REDCap Surveys with Data Analysis:**<br>
   I have skillfully managed the integration of MTurk tasks and REDCap surveys into a cohesive workflow. After extracting data from completed surveys, I perform data analysis using the R programming language. This streamlined process allows for prompt and comprehensive data analysis following survey completion, contributing to quicker insights and informed decision-making.

6. **Statistical Analysis of Patient Data to Uncover Care Patterns and Demographics:**<br>
   Through rigorous statistical tests and regression analysis, I delve into patient data to uncover valuable insights such as care patterns, demographics, and factors influencing engagement and adherence. This analytical approach enables the identification of trends, correlations, and potential causal relationships within the data. These findings are crucial for informing healthcare strategies, optimizing patient care, and enhancing engagement strategies.

These elaborations provide a comprehensive understanding of your expertise and contributions in various data-related tasks, showcasing your ability to manage data effectively, ensure data integrity, and extract meaningful insights from complex datasets.
         </p>       
     <br>
      <p style="line-height: 1.5;font-size: 18px;">
         <strong> II. Tata Consultancy Services </strong>                                           
                  <strong> System Engineer </strong>
                  <strong>Mar 2018 - July 2022</strong>
       </p>
     <br>
       <p style="line-height: 1.5;font-size: 15px;">

<strong>ETL experience working with Informatica PowerCenter 9.x</strong>:<br>

1. I have proficiently employed Informatica Power Exchange and PowerCenter 9.x to extract, transform, and load data from diverse sources, including mainframes, flat files, Teradata databases, and EDW systems.<br>

2. I have dveloped intricate ETL mappings, worklets, and reusable transformations encompassing filters, expressions, joiners, aggregators, and more, ensuring accurate and meaningful data transformation.<br>

3. I have built and maintained dynamic data pipelines supporting business intelligence, reporting, and analytics, ensuring seamless data integration and processing.<br>

4. I have played a key role in streamlining data analysis processes.Reduced data analysis time by One week by creating reusable ETL components and streamlining workflows and optimizing data-driven decision-making processes.<br>

<strong>UNIX and shell scripting for validation testing</strong>:<br>

1. Demonstrated proficiency in developing UNIX shell scripts tailored for specific validation testing requirements. Leveraged these scripts to meticulously validate data integrity and accuracy within complex datasets. Additionally, adeptly customized PLSQL scripts to further enhance the validation process, ensuring comprehensive and reliable testing outcomes. This combined approach of scripting and database manipulation underscores my commitment to thorough quality assurance and data validation practices.<br>

<strong>Performance tuning and optimization</strong>:<br>

1. Methodically identified and addressed performance bottlenecks within long-running CI/CD jobs. Employed advanced optimization techniques at various levels—source, target, mapping, and session—ensuring streamlined processes and efficient data flows.<br>
2. Leveraged the power of cloud computing, particularly in AWS, to significantly optimize ETL operations. Achieved remarkable results with a 50% reduction in processing time, alongside heightened scalability, demonstrating a clear commitment to efficient and agile data processing.<br>
3. Demonstrated proficiency in utilizing ETL tools to streamline data integration workflows. This approach led to a reduction in errors, enhancement of data quality, and notable cost savings on infrastructure, showcasing an ability to balance effectiveness and efficiency in data management.<br>

<strong>Database object migration</strong><br>

1. Skillfully managed the migration of crucial database objects across a range of environments, including Development, Testing, UAT, and Production. Ensured a smooth transition of these objects, maintaining data integrity and consistency throughout the lifecycle. This meticulous approach supported the successful deployment of applications and systems across multiple stages, contributing to a robust and reliable software development process.<br>

<strong>Documentation and Project Tracking</strong>:<br>

1. Actively partnered with both onshore and offshore data stewards and application development leads to ensure seamless project tracking using JIRA. This collaborative effort facilitated efficient communication, task management, and progress monitoring, leading to well-coordinated project execution.<br>
2. Meticulously managed ETL code repositories by implementing continuous integration practices. Conducted thorough code reviews to uphold stringent code quality and adherence to standards, ensuring the reliability and maintainability of the ETL processes.<br>
3. Demonstrated adeptness in articulating findings and insights to stakeholders in a clear and impactful manner. This effective communication approach facilitated informed decision-making and fostered a shared understanding of project progress and outcomes.<br>

<strong>Leadership</strong>:<br>

1. Offered valuable technical guidance and oversaw review processes in a dynamic and fast-paced setting, demonstrating the ability to work effectively with minimal supervision. Ensured high-quality outcomes and maintained governance standards despite the challenging environment.<br>

2. Mentored a team of 7 junior developers, sharing best practices for ETL job development using Informatica. Additionally, adeptly communicated project status updates to foster transparency and cohesion within the team, contributing to efficient workflows.<br>

3. Provided expert guidance and comprehensive training to junior ETL developers. Covered essential ETL development methodologies, data modeling best practices, and fundamental data integration concepts. This mentoring effort empowered the team with essential skills and knowledge for optimized data workflows.<br>
</p>



